llm:
  model_name: "llama-3.1-8b-instant"
  temperature: 0.2
  json_mode: True 
  